---
title:  "부스트캠프 AI Tech 3주차 주간 학습 정리"
excerpt: "Level 1 Ustage 3주차"
categories:
  - Ustage
tags:
  - [ustage]
toc: true
toc_sticky: false
date: 2021-08-17
author_profile: false
---
**Day 1**
===

- 학습 강의 : PyTorch 1 ~ 3강
- 과제 : [필수과제] Custom Model 개발하기

## 1. 강의 복습
### **PyTorch** <br/>

**1강 : Introduction to PyTorch**
- PyTorch와 TensorFlow의 차이점 :
    - PyTorch는 Define by Run(Dynamic Computational Graph, DCG) 방식으로 실행을 하면서 그래프를 생성한다. 논문을 쓰거나 개발 중일 때 용이하다.
    - TensorFlow는 Define and Run 방식으로 그래프를 먼저 정의하고 실행 시점에 데이터를 feed한다. 개발 후 배포할 때 용이하다.

<br/>

**2강 : PyTorch Basics**
- PyTorch의 연산의 장점은 Numpy + AutoGrad에 있다.
- torch.FloatTensor()로 Tensor를 생성할 수 있다.
- list나 ndarray를 사용하여 Tensor를 생성할 수도 있다. ndarray의 경우 torch.from_numpy(nd_array) 형식으로 생성 가능
- view, squeeze, unsqueeze 등으로 tensor의 차원을 조정할 수 있다.
- 행렬곱셈 연산은 dot이 아닌 mm을 사용, mm은 matmul과 달리 broadcasting을 지원하지 않는다.
- backward 함수를 사용해 자동 미분이 가능하다.  
```python
a = torch.tensor([2., 3.], requires_grad = True)
b = torch.tensor([6., 4.], requires_grad = True)
Q = 3*a**3 - b**2
external_grad = torch.tensor([1., 1.])
Q.backward(gradient = external_grad)
a.grad 
>>> tensor([36., 81.])
b.grad
>>> tensor([-12., -8.])
```
<br/>

**3강 : PyTorch 프로젝트 구조 이해하기**
- 프로젝트 템플릿 이용하기
- 코랩을 ssh로 연결하여 vscode로 작업환경 세팅하기(ngrox 이용)

<br/>

## 2. 새로 알게된 내용 / 고민한 내용 (강의, 과제, 퀴즈)
- 필수 과제를 통해 torch 모듈에 존재하는 여러 수학적 연산, indexing에 대해 공부했고 특히 gather함수의 실습을 통해 Tensor의 dim에 따른 연산을 더 잘 이해할 수 있었다.
- hook에 대한 개념을 배웠고 이를 forward, backward 함수에 적용하는 것을 배웠다.
- apply에 대해서 배웠고 hook을 이용해 forward함수에 변화를 줄 수 있다는 것을 알게 되었다.

## 3. 참고할 만한 자료
- **부스트코스 제공 자료**
  - [Pytorch Template](https://github.com/victoresque/pytorch-template){:target="_blank"} 
  - [Pytorch Template 2](https://github.com/FrancescoSaverioZuppichini/PyTorch-Deep-Learning-Template){:target="_blank"}
  - [Pytorch Lightning Template](https://github.com/PyTorchLightning/deep-learning-project-template){:target="_blank"}
  - [Pytorch Lightning](https://www.pytorchlightning.ai/){:target="_blank"}
  - [Pytorch Lightning + NNI Boilerplate](https://github.com/davinnovation/pytorch-boilerplate){:target="_blank"}

## 4. 피어세션
- 문석암 캠퍼님의 github의 pull request에 대한 설명과 적용 과정
- 이예빈 캠퍼님의 당일 강의 요약
- 자세한 내용은 [Peer Session](https://github.com/round26/round26/wiki/Week3_Day1){:target="_blank"}{:target="_blank"} 참조

---
---

**Day 2**
===

- 학습 강의 : DL Basic 4 ~ 5강
- 과제 : [필수과제] Custom Dataset 과제

## 1. 강의 복습
### **PyTorch** <br/>

**4강 : AutoGrad & Optimizer**
- 하나의 Layer를 하나의 레고블럭으로 생각하면 편하다. 결국 딥러닝 모델은 각각의 레고블럭을 정의하고 이러한 레고블럭들을 연결시킨 것이다. (블록 반복의 연속)
- torch.nn.Module은 딥러닝을 구성하는 Layer의 base class이다.
  - 기본적으로 Input, Output, Forward, Backward, 그리고 학습의 대상이 되는 parameter(tensor)를 정의한다.
- nn.Parameter(Tensor 객체의 상속객체)를 통해 학습의 대상이 되는 parameter를 정의한다.
  - ***nn.module 내에서 attribute가 될 때에는 required_grad = True로 지정해서 학습의 대상이 된다.**
  - 대부분의 layer에서는 weight 값들이 지정되어 있다.
- backward 함수를 통해 layer에 존재하는 parameter들의 미분을 진행(loss function 미분)
- optimizer.zero_grad()를 이용해 이전의 gradient 값이 현재의 gradient 계산에 영향을 주는 것을 제거하기 위해 초기화

<br/>

**5강 : Dataset & Dataloader**
- Dataset class의 __getitem__() method를 이용해 하나의 데이터를 불러올 때 반환하는 방식을 결정한다.
- Data 형태에 따라 Dataset class의 각 함수를 다르게 정의해야 한다.
- DataLoader는 Data의 Batch를 생성해주는 클래스
- collate_fn은 Variable length를 정의해주고 padding을 해줄 때 많이 사용한다.(시퀀스 데이터 처리)

<br/>

## 2. 새로 알게된 내용 / 고민한 내용 (강의, 과제, 퀴즈)
- 필수 과제를 통해 Dataset class와 DataLoader class의 여러 파라미터와 적용 방법 등을 배웠다.
- transform class를 통해 이미지를 tensor로 바꿀 수 있고 이미지의 Data Augumetation 할 수 있다. 
- Custom Dataset을 만드는 연습을 했고 이 과정에서 pandas를 다시 복습하였고 tqdm에 대해 알게 되었다.
  - __init__, __len__, __getitem__ method를 정의하면서 각 method의 역할과 데이터 셋을 불러오고 전처리하여 처리하는 과정을 직접 실습하면서 배울 수 있었다.
- torch에서 지원해주는 여러 Dataset에 대해 살펴볼 수 있었다.(MNIST, AG_NEWS 등)

## 3. 참고할 만한 자료
- **부스트코스 제공 자료**
  - [Pytorch로 Linear Regression하기](https://towardsdatascience.com/linear-regression-with-pytorch-eb6dedead817){:target="_blank"} 
  - [Pytorch로 Logistic Regression하기](https://medium.com/dair-ai/implementing-a-logistic-regression-model-from-scratch-with-pytorch-24ea062cd856){:target="_blank"}
  - [Pytorch Dataset, Dataloader 튜토리얼](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html){:target="_blank"}

## 4. 피어세션
- 1일차 필수과제에 대한 질의응답
- 문석암 캠퍼님의 당일 강의 요약
- 1일차 알고리즘 문제 풀이 코드 리뷰
- 자세한 내용은 [Peer Session](https://github.com/round26/round26/wiki/Week3_Day2){:target="_blank"}{:target="_blank"} 참조

---
---

**Day 3**
===

- 학습 강의 : DL Basic 6 ~ 7강
- 과제 : [선택과제] Transfer Learning + Parameter Tuning

## 1. 강의 복습
### **PyTorch** <br/>

**6강 : 모델 불러오기**
- 최근 AI의 트렌드는 Backbone이라고 하는 기본적인 모델(이미 학습되어 있는)을 가져와 원하는 데이터를 학습시키는 것이 대세이다. -> fine tuning이라고 불린다.
- 학습의 결과를 저장할 필요가 있기 때문에 PyTorch에서는 model.save()라는 함수를 지원해준다.
  - 모델 형태(architecture)와 paramter를 저장
  - 학습 중간 과정의 저장을 통해 최선의 결과 모델 선택(Early stopping)
- `model.state_dict()` : 모델의 paramter를 표시, `torch.save(model.state_dict(), os.paht.join(MODEL_PATH, "model.pt"))` 형식으로 모델 parameter 저장, `model.load_state_dict(torch.load(...))` 형식으로 parameter를 같은 형태의 모델에 load
- torch.save(model, ...)은 모델 형태 저장, torch.load(...)은 모델 형태 load -> pickle 형태로 저장
- checkpoints : 학습의 중간 결과를 저장하여 최선의 결과를 선택
  - epoch, loss, metric을 함께 저장하여 확인
  - colab에서 지속적인 학습을 위해 필요
- Transfer learning : 다른 데이터셋으로 만든 모델을 현재 데이터에 적용
  - 대용량 데이터셋으로 만든 모델의 경우 성능이 좋기 때문에 이를 활용
  - 현재 딥러닝에서 가장 일반적인 학습 방법이다.
  - TorchVison이나 NLP의 경우 HuggingFace에서 모델을 지원
- Freezing : pretrained model 활용 시 모델 일부분의 parameter를 변경하지 못하게 하는 것(`requires_grad = False`로 바꿔준다.)

<br/>

**7강 : Monitoring tools for PyTorch**
- 학습 모터닝 도구에는 Tensorboard, weight & biases 등이 있다.(시각화 도구)
- Tensorboard
  - scalar : matric(Acc, Loss) 등 상수 값의 연속(epoch)을 표시
  - graph : 모델의 computational graph 표시
  - histogram : weight 등 값의 분포를 표시
  - image : 예측 값과 실제 값을 비교 표시
  - mesh : 3d 형태의 데이터를 표형하는 도구
- torchvision.utils.make_grid(image)를 사용하면 image grid를 생성해준다.
- weight&biases : MLops 도구 중 하나로 볼 수 있다.
  - 협업, code versioning, 실험 결과 기록 등을 제공

<br/>

## 2. 새로 알게된 내용 / 고민한 내용 (강의, 과제, 퀴즈)
- 딥러닝의 학습 방법은 Transfer learning이 가장 대세이다.
- 모델을 불러오고 fine tuning을 하는 방법, Freezing에 대한 개념을 배웠다.
- 학습 중간 결과를 확인하기 위해 Tensorboard, weight & bias 등의 도구를 사용한다. 시각화 도구를 이용함으로써 좀 더 편하게 paramter 값의 변화를 histogram으로 살펴볼 수 있고 이를 공유하기도 쉽다.

## 3. 참고할 만한 자료
- **부스트코스 제공 자료**
  - [Computer Vision 모델 레포지토리](https://github.com/rwightman/pytorch-image-models){:target="_blank"} 
  - [Segmentation 모델 레포지토리](https://github.com/qubvel/segmentation_models.pytorch){:target="_blank"}
  - [Pytorch Dataset, Dataloader 튜토리얼](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html){:target="_blank"}
  - [WandB 모니터링 도구](https://wandb.ai/site){:target="_blank"}
  - [Pytorch Tensorboard](https://pytorch.org/docs/stable/tensorboard.html){:target="_blank"}
  - [Pytorch Lightning Logger 목록들](https://pytorch-lightning.readthedocs.io/en/stable/extensions/logging.html){:target="_blank"}

## 4. 피어세션
- 김다인 캠퍼님의 강의 요약 및 캐글 간단 설명
- 필수과제 1, 2에 대한 질의 응답
- Attention Is All You Need 가볍게 읽어보기
- 차주 강의요약 발표자 선정
- 자세한 내용은 [Peer Session](https://github.com/round26/round26/wiki/Week3_Day3){:target="_blank"}{:target="_blank"} 참조

---
---

**Day 4**
===

- 학습 강의 : DL Basic 8 ~ 10강

## 1. 강의 복습
### **PyTorch** <br/>

**8강 : Multi-GPU 학습**
- 
<br/>

**9강 : Hyperparameter Tuning**
- 
<br/>

**10강 : PyTorch Troubleshooting**
- 
<br/>

## 2. 새로 알게된 내용 / 고민한 내용 (강의, 과제, 퀴즈)
- 

## 3. 참고할 만한 자료
- **부스트코스 제공 자료**
  - [Computer Vision 모델 레포지토리](https://github.com/rwightman/pytorch-image-models){:target="_blank"} 
  - [Segmentation 모델 레포지토리](https://github.com/qubvel/segmentation_models.pytorch){:target="_blank"}
  - [Pytorch Dataset, Dataloader 튜토리얼](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html){:target="_blank"}
  - [WandB 모니터링 도구](https://wandb.ai/site){:target="_blank"}
  - [Pytorch Tensorboard](https://pytorch.org/docs/stable/tensorboard.html){:target="_blank"}
  - [Pytorch Lightning Logger 목록들](https://pytorch-lightning.readthedocs.io/en/stable/extensions/logging.html){:target="_blank"}

## 4. 피어세션
- 
- 자세한 내용은 [Peer Session](https://github.com/round26/round26/wiki/Week3_Day3){:target="_blank"}{:target="_blank"} 참조